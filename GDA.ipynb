{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f827723-14c2-48f7-b236-84f21829a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: x = 0, f(x) = 9\n",
      "Iteration 10: x = -2.6778774528, f(x) = 0.10376293541461834\n",
      "Iteration 20: x = -2.9654123548617948, f(x) = 0.0011963051962045057\n",
      "Iteration 30: x = -2.996286179882144, f(x) = 1.379245986932176e-05\n",
      "Iteration 40: x = -2.9996012316012646, f(x) = 1.5901623662273323e-07\n",
      "Iteration 50: x = -2.9999571825692186, f(x) = 1.833331708667174e-09\n",
      "Iteration 60: x = -2.999995402513377, f(x) = 2.113864638886298e-11\n",
      "Convergence reached after 60 iterations.\n",
      "\n",
      "Local minimum of f(x) is at x = -2.999995402513377, with f(x) = 2.113864638886298e-11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function\n",
    "def f(x):\n",
    "    return x**2 + 6*x + 9\n",
    "\n",
    "# Define the derivative of the function\n",
    "def f_derivative(x):\n",
    "    return 2*x + 6\n",
    "\n",
    "# Gradient Descent algorithm\n",
    "def gradient_descent(starting_x, learning_rate, precision, max_iters):\n",
    "    x = starting_x\n",
    "    for i in range(max_iters):\n",
    "        grad = f_derivative(x)\n",
    "        x_new = x - learning_rate * grad  # Update step\n",
    "        step_size = abs(x_new - x)\n",
    "        \n",
    "        # Print progress every 10 iterations\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Iteration {i}: x = {x}, f(x) = {f(x)}\")\n",
    "        \n",
    "        # Check if step size is below the precision threshold\n",
    "        if step_size < precision:\n",
    "            print(f\"Convergence reached after {i} iterations.\")\n",
    "            break\n",
    "        \n",
    "        x = x_new\n",
    "    \n",
    "    return x, f(x)\n",
    "\n",
    "# Parameters\n",
    "starting_x = 0          # Starting point\n",
    "learning_rate = 0.1     # Learning rate (step size)\n",
    "precision = 1e-6        # Precision to stop the algorithm\n",
    "max_iters = 1000        # Maximum number of iterations\n",
    "\n",
    "# Run Gradient Descent\n",
    "min_x, min_f_x = gradient_descent(starting_x, learning_rate, precision, max_iters)\n",
    "print(f\"\\nLocal minimum of f(x) is at x = {min_x}, with f(x) = {min_f_x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837332d4-dcd9-46d6-aac7-f7a3e3d08dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
